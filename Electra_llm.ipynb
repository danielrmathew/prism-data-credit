{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcaeada-6eac-401a-90e5-338149415325",
   "metadata": {},
   "source": [
    "# ELECTRA LLM\n",
    "\n",
    "## Considerations:\n",
    "\n",
    "- __Combining Features__: Use ELECTRA embeddings for the memo text, and concatenate them with normalized versions of your numeric features (amount and date) for a combined representation.\n",
    "- __Optimizing for Inference__: Quantization (e.g., 8-bit) can improve inference times without a significant loss in accuracy, which helps meet your latency requirements.\n",
    "- __Class Imbalance__: During fine-tuning, focus on weighted cross-entropy or focal loss to handle the imbalance effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bb843a-fc31-40d9-a601-f2edb726e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54056432-13ce-4de9-82ef-19624caa56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datasets import Dataset, ClassLabel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f165b8b-52e1-4475-aee2-79b2d3faeb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflows = pd.read_parquet('ucsd-outflows.pqt')\n",
    "outflows = outflows[outflows.category != outflows.memo].reset_index(drop=True)\n",
    "outflows.posted_date = pd.to_datetime(outflows.posted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6960a576-10ae-45d1-8318-dad275d8f72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month_num</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>TST* Casa Del Rio - Exp Fairlawn OH 09/24</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Buffalo Wild Wings</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Oculus CA 04/16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>LOS GIRASOLES STOW OH 03/08</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>BUZZIS LAUNDRY 1 OH 03/28</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prism_consumer_id prism_account_id  \\\n",
       "0                  0            acc_0   \n",
       "1                  0            acc_0   \n",
       "2                  0            acc_0   \n",
       "3                  0            acc_0   \n",
       "4                  0            acc_0   \n",
       "\n",
       "                                        memo  amount posted_date  \\\n",
       "0  TST* Casa Del Rio - Exp Fairlawn OH 09/24  0.0001  2022-09-26   \n",
       "1                         Buffalo Wild Wings  0.0001  2022-09-12   \n",
       "2                            Oculus CA 04/16  0.0000  2022-04-18   \n",
       "3                LOS GIRASOLES STOW OH 03/08  0.0001  2022-03-09   \n",
       "4                  BUZZIS LAUNDRY 1 OH 03/28  0.0000  2022-03-29   \n",
       "\n",
       "              category  day_of_week  month_num  is_weekend  \n",
       "0   FOOD_AND_BEVERAGES            0          9       False  \n",
       "1   FOOD_AND_BEVERAGES            0          9       False  \n",
       "2  GENERAL_MERCHANDISE            0          4       False  \n",
       "3   FOOD_AND_BEVERAGES            2          3       False  \n",
       "4  GENERAL_MERCHANDISE            1          3       False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "outflows['amount'] = scaler.fit_transform(outflows[['amount']])\n",
    "\n",
    "outflows['day_of_week'] = outflows.posted_date.dt.dayofweek\n",
    "outflows['month_num'] = outflows.posted_date.dt.month\n",
    "outflows['is_weekend'] = outflows.day_of_week >= 5\n",
    "\n",
    "outflows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe5415-730c-479f-a716-308ea9281bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b513bf29-12bc-40a8-8e0f-32db2686441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FOOD_AND_BEVERAGES', 'GENERAL_MERCHANDISE', 'GROCERIES', 'PETS',\n",
       "       'TRAVEL', 'MORTGAGE', 'OVERDRAFT', 'EDUCATION', 'RENT'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = outflows.category.unique()\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1301123-f15b-447b-ace2-464650180d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: categories[i] for i in range(len(categories))}\n",
    "label2id = {categories[i]: i for i in range(len(categories))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57a0c44-80e9-44a7-aa24-19f0741f656e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'FOOD_AND_BEVERAGES',\n",
       " 1: 'GENERAL_MERCHANDISE',\n",
       " 2: 'GROCERIES',\n",
       " 3: 'PETS',\n",
       " 4: 'TRAVEL',\n",
       " 5: 'MORTGAGE',\n",
       " 6: 'OVERDRAFT',\n",
       " 7: 'EDUCATION',\n",
       " 8: 'RENT'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c130bd04-b238-4328-9b7d-46f4ac9a5bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FOOD_AND_BEVERAGES': 0,\n",
       " 'GENERAL_MERCHANDISE': 1,\n",
       " 'GROCERIES': 2,\n",
       " 'PETS': 3,\n",
       " 'TRAVEL': 4,\n",
       " 'MORTGAGE': 5,\n",
       " 'OVERDRAFT': 6,\n",
       " 'EDUCATION': 7,\n",
       " 'RENT': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107c5081-c12e-4e87-8dab-82941bf3122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FOOD_AND_BEVERAGES',\n",
       " 'GENERAL_MERCHANDISE',\n",
       " 'GROCERIES',\n",
       " 'PETS',\n",
       " 'TRAVEL',\n",
       " 'MORTGAGE',\n",
       " 'OVERDRAFT',\n",
       " 'EDUCATION',\n",
       " 'RENT']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(label2id.keys())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e416b50-7fdd-4421-bc09-0c323b722bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>memo</th>\n",
       "      <th>amount</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>category</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month_num</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>TST* Casa Del Rio - Exp Fairlawn OH 09/24</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Buffalo Wild Wings</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>Oculus CA 04/16</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>LOS GIRASOLES STOW OH 03/08</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2022-03-09</td>\n",
       "      <td>FOOD_AND_BEVERAGES</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>acc_0</td>\n",
       "      <td>BUZZIS LAUNDRY 1 OH 03/28</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>GENERAL_MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prism_consumer_id prism_account_id  \\\n",
       "0                  0            acc_0   \n",
       "1                  0            acc_0   \n",
       "2                  0            acc_0   \n",
       "3                  0            acc_0   \n",
       "4                  0            acc_0   \n",
       "\n",
       "                                        memo  amount posted_date  \\\n",
       "0  TST* Casa Del Rio - Exp Fairlawn OH 09/24  0.0001  2022-09-26   \n",
       "1                         Buffalo Wild Wings  0.0001  2022-09-12   \n",
       "2                            Oculus CA 04/16  0.0000  2022-04-18   \n",
       "3                LOS GIRASOLES STOW OH 03/08  0.0001  2022-03-09   \n",
       "4                  BUZZIS LAUNDRY 1 OH 03/28  0.0000  2022-03-29   \n",
       "\n",
       "              category  day_of_week  month_num  is_weekend  category_id  \n",
       "0   FOOD_AND_BEVERAGES            0          9       False            0  \n",
       "1   FOOD_AND_BEVERAGES            0          9       False            0  \n",
       "2  GENERAL_MERCHANDISE            0          4       False            1  \n",
       "3   FOOD_AND_BEVERAGES            2          3       False            0  \n",
       "4  GENERAL_MERCHANDISE            1          3       False            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outflows['category_id'] = outflows.category.apply(lambda c: label2id[c])\n",
    "outflows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea886ce-3b53-4656-9bdc-f3d9528593b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e5ce0fd-301c-4d3a-ab02-7f61119cfac4",
   "metadata": {},
   "source": [
    "## Tokenize and Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e39b8de-22fb-4153-965b-b62867f92c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c256b48e-ae47-4596-bace-aa6663b95820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outflows.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e64717ec-9fb2-4a6b-8eea-023d0047fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflows = outflows.drop(columns=['prism_consumer_id', 'prism_account_id', 'category'])\n",
    "\n",
    "outflows = outflows[['memo', 'category_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91022282-ee7f-4a60-b4e6-c6c44147186e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14209782-30c3-4ab9-8abf-110bdd51ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a233081a-e4a3-43a0-8183-80d8517f4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraTokenizerFast(name_or_path='google/electra-small-discriminator', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\", clean_up_tokenization_spaces=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f04d9a8-0767-4702-b9bf-18e1079a74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(examples[\"memo\"], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    # Add additional features\n",
    "    tokens['amount'] = examples['amount']\n",
    "    tokens['day_of_week'] = examples['day_of_week']\n",
    "    tokens['month_num'] = examples['month_num']\n",
    "    tokens['is_weekend'] = examples['is_weekend']\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d4738d2-d852-4f2d-810d-3b4e994e7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memos = outflows.memo.values.tolist()\n",
    "\n",
    "tokenized_memos = tokenizer(memos, truncation=True) # potentially create col in df and feed that to MemoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f1fee9-93f7-486c-a023-9d37a7d7959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class MemoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58ce4f07-1dfa-49b1-a134-459d56645aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(len(memos) * 0.25)\n",
    "train_size = len(memos) - test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "851a4d10-4cc6-414e-b1a1-8cddf3600f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outflows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9efdb772-2ebc-4d0a-ab14-7c6cbe796e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenized_memos[:train_size]\n",
    "X_test = tokenized_memos[train_size:]\n",
    "\n",
    "y_train = outflows.category_id.values.tolist()[:train_size]\n",
    "y_test = outflows.category_id.values.tolist()[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71775083-5c30-4546-99e0-1c1156e5b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MemoDataset(X_train, y_train)\n",
    "test = MemoDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f879a26-1773-4e03-912b-c47dedee3d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979839"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f52d28b-9711-4293-840f-a4f5ae6501c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = dataset.map(tokenize_function, batched=True,) # 4 cause broken pipe error\n",
    "# num_proc=1 --> subprocessses keep failing (does not take too long though)\n",
    "\n",
    "# tokenized_dataset = dataset.map(lambda examples: tokenizer(examples[\"memo\"], padding=\"max_length\", truncation=True), batched=True,) # 4 cause broken pipe error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2d5e33c-a8b2-4cac-ad9c-0f2c89b6ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", 'memo', \"category_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2de3d9-bbce-4900-8a6c-b028e7f33cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06066159-15cd-4881-8bfb-e91da82d5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset.rename_column(\"category_id\", \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ea1430-0d95-4809-9466-8564f6f1c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split = tokenized_dataset.train_test_split(test_size=0.25)\n",
    "# train = train_test_split['train']\n",
    "# test = train_test_split['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7627f2f-0843-4da8-a018-8a35e3735a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.num_rows, test.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4402fcf4-0d6c-4c31-93f7-e3fdc6a3e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd29c6-0c87-44e3-a532-ef2d93d0dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['token_type_ids'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73a1cc-e241-4686-ab70-c4c5f79a53f7",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23c35b-81b2-4889-9753-02e26e618a27",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcb6a215-e670-4013-8abd-790c28b20ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 02:12:00.666732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-08 02:12:00.666803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-08 02:12:00.668441: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-08 02:12:00.678081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "CUDA available: True\n",
      "GPU in use: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"GPU in use:\", torch.cuda.current_device())\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cb28c08-087c-4493-b0f6-a8a153070f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, ElectraForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "725e2e8b-6707-4031-a4ec-d6a98a126f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a34b10e-de9f-4e5d-b915-30a0da55e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTORCH_CUDA_ALLOC_CONF=\"expandable_segments:True\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1389a0fb-4d4a-4a2c-9b6f-40b235c13a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels = 9\n"
     ]
    }
   ],
   "source": [
    "num_labels = outflows.category_id.nunique() # should be 9\n",
    "print(f'number of labels = {num_labels}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d377d054-a0c2-4a8d-a469-62202d94a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "931a624d-5832-4296-802f-4efa3bb08623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=ElectraTokenizerFast(name_or_path='google/electra-small-discriminator', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4f90ba0-3bb4-4e5c-af03-fd4fcd3d88a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at SALT-NLP/FLANG-ELECTRA and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    \"SALT-NLP/FLANG-ELECTRA\", num_labels=num_labels, id2label=id2label, label2id=label2id, #problem_type=\"multi_label_classification\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6fcb136-d49a-46ce-b76b-a009d5994aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./electra_llm/results\",              # output directory where model checkpoints will be saved\n",
    "    num_train_epochs=3,                  # number of epochs\n",
    "    # fp16=True,                           # enable mixed precisioning, may speed up training\n",
    "    per_device_train_batch_size=8,       # batch size for training\n",
    "    per_device_eval_batch_size=64,       # batch size for evaluation\n",
    "    warmup_steps=500,                    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                   # strength of weight decay\n",
    "    logging_dir=\"./electra_llm/logs\",    # directory to store logs\n",
    "    logging_steps=10,                    # log every 10 steps\n",
    "    eval_strategy=\"epoch\",               # evaluate after each epoch\n",
    "    save_strategy=\"epoch\",               # save model after each epoch\n",
    "    load_best_model_at_end=True,         # load the best model when finished training\n",
    "    metric_for_best_model=\"accuracy\",    # metric to determine the best model\n",
    "    logging_first_step=True,             # log first step\n",
    "    # use_cpu=False,\n",
    "    dataloader_num_workers=8,             # have 8 cpus to use\n",
    "    report_to='tensorboard',\n",
    "    # disable_tqdm=False,                   # Enable tqdm progress bar\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e9b7ba8-ecd5-47a4-a34d-45fa4a185eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google/electra-small-discriminator\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"SALT-NLP/FLANG-ELECTRA\", num_labels=num_labels, id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32cada86-6c3f-4a78-9e10-2ad9dc3029fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "469225db-cdf7-4f7c-a21d-622521aae101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6f0f4a5aee439ba3439f0b704c21db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                          # your model\n",
    "    args=training_args,                   # training arguments\n",
    "    data_collator=data_collator,          # collator for batching\n",
    "    compute_metrics=compute_metrics,      # metrics function\n",
    "    processing_class=tokenizer,           # tokenizer\n",
    "    train_dataset=train,          # training dataset\n",
    "    eval_dataset=test             # evaluation dataset\n",
    ")\n",
    "\n",
    "model.to('cuda')\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fc1340d-39d5-40fd-aeab-dfb4f75d90ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_9218/609361498.py\", line 8, in __getitem__\n    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n                                                        ^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'list' object has no attribute 'items'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2427\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2425\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2426\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2427\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2429\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:5045\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5043\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5045\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5046\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5047\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_9218/609361498.py\", line 8, in __getitem__\n    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n                                                        ^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'list' object has no attribute 'items'\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e085e1b-19cc-4102-973e-d844b7237052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464be329-ff98-49ff-a93c-a290d4555eba",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b7e88-960f-48a8-85d0-29bdeeec0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f0018-95e6-49d5-a1f3-659a0fb03c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./electra_llm/final_model\")\n",
    "tokenizer.save_pretrained(\"./electra_llm/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bafdf-a429-426c-b7f0-f416417cc248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83d1e3-e28b-4558-a050-3f861639df9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fb4c8-1c3a-4d5b-9903-bb99eb7a0d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef1f21-60f7-42c4-95a0-297f900756b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee159d-5304-4730-be6e-1ce7a810eeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "96cb9601-776c-47f9-813f-abc5d3356d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, ElectraForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31f34533-15e3-4bfe-a1f5-ee4edeb94a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08522b8d6b3a415ea8ae2c7e9019fe08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/336 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9d1f153c6a44f7a314ddeaeff13047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f140ee86f0f44f3fba9bec61181a9ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e158b9a0d54c8492a9d28c71c2cd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a026ba44a4e145cba734f568fa8d7919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd76139b8d449ce9126b37d80ea3830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/electra-base-emotion\")\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"bhadresh-savani/electra-base-emotion\", problem_type=\"multi_label_classification\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6376e116-a9c7-498a-9732-883b3b1239b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_ids = torch.arange(0, logits.shape[-1])[torch.sigmoid(logits).squeeze(dim=0) > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5c6175ce-bbe6-4307-87f7-99f73773d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(model.config.id2label)\n",
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    \"bhadresh-savani/electra-base-emotion\", num_labels=num_labels, problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "labels = torch.sum(\n",
    "    torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1\n",
    ").to(torch.float)\n",
    "loss = model(**inputs, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "25f4a694-36a2-4ea3-b9a2-f184becce056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: ['sadness']\n"
     ]
    }
   ],
   "source": [
    "text = \"I'm am not feeling sad.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get predictions without gradient calculation\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# Apply sigmoid to get probabilities\n",
    "probabilities = torch.sigmoid(logits).squeeze()\n",
    "\n",
    "# Set a threshold (e.g., 0.5) to decide on the predicted labels\n",
    "threshold = 0.5\n",
    "predicted_class_ids = torch.where(probabilities > threshold)[0]\n",
    "\n",
    "# Map predicted class IDs to class names\n",
    "predicted_labels = [model.config.id2label[class_id.item()] for class_id in predicted_class_ids]\n",
    "\n",
    "print(\"Predicted labels:\", predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8a7a1eee-5bad-4a87-ac08-c335350d31ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2e36c-62f4-4582-984e-d983e4542e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7894f7-8a28-44f5-8282-db46bfea5888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d87e92-61ac-41fe-ae5f-8ded797a4a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037e29e-c001-4c39-b25f-c9b6e4365276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b833e-9370-4d68-a411-895ee5253bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ffacf-b682-473a-9774-c179711e224e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375993c-0a17-4207-b270-0f2868bb0696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8f404-2279-467b-aa81-43920ce896a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358df50a-b068-4bc0-a113-7be9b883826f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537917f-e14c-4560-a47d-ddddaca69af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba82a5e-44b3-4b13-92df-31236a9b3241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffb627-5bc3-45e9-bc8c-aeb5338a1d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57776f22-3455-41d9-81b3-cbd7cc98ca06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05f852-1c7b-4214-aa4f-4d19df6262cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bb245-310f-425a-837c-3842e9160f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9decedf-a9c8-4433-b486-9e387549e842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b6b2b-de42-4286-a49a-0bd3f03a0e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f936377-54c5-476a-9f94-75a371f87d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdede57f-c145-461e-8c03-f50b1c9cebc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573ef2c-2659-4e01-88ee-92a75b735ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2bf40e-8c53-4cd5-90a1-612ba202ff67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76ae30-e006-4582-9cc5-b24a8abe2b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9de313-82da-49db-aeb6-9a37b4316225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
