<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building Better Credit Scores</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-..." crossorigin="anonymous" referrerpolicy="no-referrer" />

</head>
<body>
    <header>
        <div class="overlay"></div>
        <div class="text-box">
            <h1>Building Better Credit Scores</h1>
            <h2>Machine Learning and NLP for Optimized Risk Assessment</h2>
            <p>By Aman Kar, Daniel Mathew, Tracy Pham</p>
            <a href="https://github.com/danielrmathew/prism-data-credit" target="_blank" class="github-link">
                <img src="figures/github-mark-white.png" alt="GitHub Logo" class="github-logo">
                View on GitHub
            </a>
        </div>
    </header>
       
    <nav class="navbar">
        <ul>
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#methods">Methods</a></li>
            <li><a href="#models">Models</a></li>
            <li><a href="#results">Results</a></li>
            <li><a href="#conclusion">Conclusion</a></li>
        </ul>
    </nav>
    <main>
        <section id="introduction">
            <h2>Introduction</h2>
            <figure class="image-group">
                <img src="figures/traditional-model.png" alt="Traditional Credit Scoring Model (FICO Score)">
                <figcaption>Traditional Credit Scoring Model (FICO Score)</figcaption>
            </figure>
            <p>Credit scores are pivotal in today’s financial landscape, influencing everything from rental eligibility to access to 
                health insurance, yet the formula for calculating creditworthiness has long been shrouded in mystery and often overlooks 
                important nuances. Typically, the credit score is determined based on five factors: payment history, amount owed, new 
                credit, credit history, and credit mix. This structure can place individuals with limited credit history, especially 
                young adults who are just starting out building their credit, at a compounded disadvantage, restricting their access to 
                loans, credit cards, employment opportunities, and insurance. Our proposed Cash Score model aims to address these limitations by 
                providing a more comprehensive measure of creditworthiness. The Cash Score model leverages detailed account transaction 
                data to predicts the probability of defaulting on a loan (as known as loan delinquency). This approach highlights 
                the potential for transaction-based credit evaluation to more accurately assess financial risk and improve access to credit, 
                offering a fairer alternative to traditional credit scoring methods.</p>
            <figure class="improved-model">
                <img src="figures/model-pipeline.png" alt="Improved Credit Risk Model">
                <figcaption>Improved Credit Scoring Model Pipeline</figcaption>
            </figure>
            We adopted an iterative approach to model development, emphasizing continuous refinement and enhancement
            of features alongside model selection and performance evaluation. We began with logistic regression to establish a 
            baseline and identify key features. As the process evolved, we integrated more advanced algorithms like 
            HistGradientBoosting (HistGB), CatBoost, LightGBM, and XGBoost, chosen for their ability to handle complex data patterns.
            Throughout the iterations, we focused on refining and enhancing feature generation, selecting the most relevant ones to 
            improve the model’s performance. This iterative process allows us to optimize the model’s predictive power.
        </section>

        <section id="methods">
            <h2>Methods</h2>
            <h3>Data Description</h3>
            <p>Our analysis leverages four key datasets that provide insights into consumer accounts, transaction
                histories, and credit scores. As the datasets were prepared and preprocessed by Prism
                Data, this minimized the need for extensive data cleaning. Our primary focus in terms of
                data cleaning was reviewing the data for consistency, addressing any remaining missing
                values, standardizing categorical variables, and structuring time-series data to optimize it
                for modeling.</p>

            <p>Below are the heads of the datasets used in this analysis. Click on each section 
                to expand and view the data, which includes account details, consumer credit scores, transactions,
                and category mappings.</p>
            
    <div class="container">
        <h2> Key Data Tables</h2>

        <div class="accordion">
            <button class="accordion-btn">Account Dataset</button>
            <div class="panel">
                <table>
                    <thead>
                        <tr>
                            <th>prism_consumer_id</th>
                            <th>prism_account_id</th>
                            <th>account_type</th>
                            <th>balance_date</th>
                            <th>balance</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>3,023</td><td>0</td><td>SAVINGS</td><td>2021-08-31</td><td>90.57</td></tr>
                        <tr><td>3,023</td><td>1</td><td>CHECKING</td><td>2021-08-31</td><td>225.95</td></tr>
                        <tr><td>4,416</td><td>2</td><td>SAVINGS</td><td>2022-03-31</td><td>15,157.17</td></tr>
                        <tr><td>4,416</td><td>3</td><td>CHECKING</td><td>2022-03-31</td><td>66.42</td></tr>
                        <tr><td>4,227</td><td>4</td><td>CHECKING</td><td>2021-07-31</td><td>7,042.90</td></tr>
                    </tbody>
                </table>
                <p>The acctDF.csv dataset contains detailed information about consumer financial accounts, including 
                    account types, balances, and balance dates. The table above displays a preview of the dataset, 
                    showing each consumer’s account balances on specific dates.</p>
            </div>
        </div>

        <div class="accordion">
            <button class="accordion-btn">Consumer Dataset</button>
            <div class="panel">
                <table>
                    <thead>
                        <tr>
                            <th>prism_consumer_id</th>
                            <th>evaluation_date</th>
                            <th>credit_score</th>
                            <th>DQ_TARGET</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>0</td><td>2021-09-01</td><td>726</td><td>0</td></tr>
                        <tr><td>1</td><td>2021-07-01</td><td>626</td><td>0</td></tr>
                        <tr><td>2</td><td>2021-05-01</td><td>680</td><td>0</td></tr>
                        <tr><td>3</td><td>2021-03-01</td><td>734</td><td>0</td></tr>
                        <tr><td>4</td><td>2021-10-01</td><td>676</td><td>0</td></tr>
                    </tbody>
                </table>
                <p>This displays a preview of consDF.csv dataset which provides credit scores, evaluation
                    dates, and delinquency targets for each consumer. This dataset is essential for building a
                    model of credit risk, as it contains direct indicators of a consumer’s creditworthiness. The
                    delinquency targets serves as the dependent variable, enabling us to assess our model’s
                    performance in predicting credit risk.</p>
            </div>
        </div>

        <div class="accordion">
            <button class="accordion-btn">Transaction Dataset</button>
            <div class="panel">
                <table>
                    <thead>
                        <tr>
                            <th>prism_consumer_id</th>
                            <th>prism_transaction_id</th>
                            <th>category</th>
                            <th>amount</th>
                            <th>credit_or_debit</th>
                            <th>posted_date</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>3,023</td><td>0</td><td>4</td><td>0.05</td><td>CREDIT</td><td>2021-04-16</td></tr>
                        <tr><td>3,023</td><td>1</td><td>12</td><td>481.56</td><td>CREDIT</td><td>2021-04-30</td></tr>
                        <tr><td>3,023</td><td>2</td><td>4</td><td>0.05</td><td>CREDIT</td><td>2021-05-16</td></tr>
                        <tr><td>3,023</td><td>3</td><td>4</td><td>0.07</td><td>CREDIT</td><td>2021-06-16</td></tr>
                        <tr><td>3,023</td><td>4</td><td>4</td><td>0.06</td><td>CREDIT</td><td>2021-07-16</td></tr>
                    </tbody>
                </table>
                <p>The trxnDF.csv dataset records individual transactions, including
                    transaction categories IDs, amounts, and whether the transaction was a credit or debit.
                    These transactional data are vital for modeling consumer behavior, such as income sources,
                    spending habits, and cash flow.</p>
            </div>
        </div>

        <div class="accordion">
            <button class="accordion-btn">Category Mappings</button>
            <div class="panel">
                <table>
                    <thead>
                        <tr>
                            <th>category_id</th>
                            <th>category</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>0</td><td>SELF_TRANSFER</td></tr>
                        <tr><td>1</td><td>EXTERNAL_TRANSFER</td></tr>
                        <tr><td>2</td><td>DEPOSIT</td></tr>
                        <tr><td>3</td><td>PAYCHECK</td></tr>
                        <tr><td>4</td><td>MISCELLANEOUS</td></tr>
                    </tbody>
                </table>
                <p> The cat_map.csv dataset maps transaction categories to their corresponding cate-
                    gory IDs, allowing us to classify and interpret the transactions effectively.Table 4 shows an
                    excerpt of this category mapping.</p>
            </div>
        </div>
    </div>
    <p>It is important to note that, in compliance with the Equal Credit Opportunity Act (ECOA),
        we excluded specific transaction categories that could introduce bias in credit decision-making. 
        Categories related to child dependents, healthcare and medical expenses, unemployment benefits, education,
        and pensions have been removed to ensure that our model does not unintentionally discriminate based on 
        protected attributes.</p>
            
            <h3>Feature Generation</h3>
            <p>We engineered features to capture financial behavior through transaction history, balance trends, 
                spending patterns, and risk indicators. Our feature generation process included:</p>
            
            <ul>
                <li><strong>Time Window Analysis:</strong> Transactions were analyzed across multiple time windows—14 
                    days, 30 days, 3 months, 6 months, and 1 year—to capture short- and long-term trends.</li>
                <li><strong>Aggregated Statistics:</strong> Summary statistics (minimum, maximum, mean, median, standard 
                    deviation, sum, count, percent of transactions) are calculated on categorical and balance trends.
                <li><strong>Risk Indicators:</strong> High-risk behaviors were identified through flagged transactions, 
                    such as gambling, using threshold-based indicators.</li>
    
                    <figure class="feat-gen-img-container">
                        <img src="../docs/figures/features-diagram.png" alt="Category-Based Feature Generation Process">
                        <figcaption>Category-Based Feature Generation Process</figcaption>
                    </figure>
                    <p>This diagram showcases our process for generating category-based features. For example, one of
                        the features created through this process is FOOD_BEVERAGES_last_14_days_mean, which
                        represents the average transaction amount within the “Food & Beverages” category over
                        the past 14 days. By analyzing these features, we aim to capture spending habits, identify
                        fluctuations in financial stability, and differentiate between various financial behaviors.</p>

                <li><strong>Other Notable Features</strong>
                    <ul>
                        <li>Sum of balances over time</li>
                        <li>Net difference between total credits and debits (credit-debit)</li>
                        <li>Change in balance over consecutive periods (balance delta)</li>
                        <li>Number of income sources and income standard deviation</li>
                    </ul>
                <li><strong>Standardization:</strong> Non-categorical features were standardized to ensure consistent 
                            scaling.</li>
                <li><strong>Resampling:</strong> SMOTE and undersampling techniques were used to rebalance the training 
                            data.</li>
            </ul>
        
            <h3>Feature Selection</h3>
            <p>To refine model input, we performed feature selection using the following techniques:</p>
            <ul>
                <li><strong>Correlation Analysis:</strong> Selected top features most correlated with delinquency using Lasso (L1) Regularization.</li>
                <li><strong>Mutual Information:</strong> Identified features with the highest mutual information score for predictive power.</li>
                <li><strong>Embedded Method:</strong> Utilized Random Forest to rank and select the most relevant features.</li>
            </ul>
        </section>
        
        
        <section id="models">
            <h2>Models</h2>
            <p>We evaluated multiple machine learning models to predict credit risk. 
                Below is a brief description of each model used in our analysis.</p>
        
                <h3>Baseline Model: Logistic Regression</h3>
                <p>We started with a logistic regression model as the baseline for predicting credit risk. This simple yet effective linear model serves as our starting point for comparison with more advanced models.</p>
            
                <h3>Advanced Modeling Approaches</h3>
                <p>To improve upon the baseline, we explored and evaluated several advanced machine learning models, including:</p>
                <ul>
                    <li><strong>Histogram-based Gradient Boosting (HistGB)</strong>: This method speeds up training by grouping data into bins. It works well for large amounts of data and makes the model faster and more memory-efficient.</li>
                    <li><strong>Categorical Boosting (CatBoost)</strong>: This is a type of gradient boosting that is good at working with data that includes categories, like "Food and Beverages" or "Rent". It prevents overfitting (the model becoming too specific to the training data) and builds trees that are more balanced, which helps the model make better predictions.</li>
                    <li><strong>Light Gradient-Boosting Machine (LightGBM)</strong>: This approach uses a method called "leaf-wise" decision trees, meaning it looks at the data in a way that helps it learn faster and use less memory. It's especially good for large datasets.</li>
                    <li><strong>Extreme Gradient Boosting (XGBoost)</strong>: This is one of the most popular gradient boosting methods. It is known to be good at avoiding mistakes due to regularization, and it can handle large data sets quickly by running in parallel on different processors, making it faster.</li>
                </ul>
                
                Each of these models is an improvement on regular decision trees and uses "boosting" to combine many trees together to improve the model’s accuracy.

                <h3>Model Evaluation</h3>
                <p>We used the following metrics to assess model performance:</p>
                <ul>
                    <li><strong>ROC AUC</strong>: Shows how well the model can tell the difference between positive and negative outcomes. Higher values mean the model is better at making this distinction.</li>
                    <li><strong>Accuracy</strong>: Tells us the percentage of times the model made a correct prediction.</li>
                    <li><strong>Precision</strong>: Measures how many of the model's positive predictions were actually correct.</li>
                    <li><strong>Recall</strong>: Shows how many of the actual positive cases were correctly identified by the model.</li>
                    <li><strong>Confusion Matrix</strong>: A table that helps us see how many predictions were correct and how many were wrong, broken down by type of error (false positive, false negative).</li>
                </ul>

        </section>
        
    <section id="results">
            <h2>Results</h2>
            <div class="results-img-container">

                <img src="../q2_result/figures/roc_auc_cs_models.png" alt="Results">
                <img src="../q2_result/figures/roc_auc_no_cs_models.png" alt="Results">

            </div>
    <p>The ROC curves below illustrate the trade-off between the true positive rate and the false positive rate for each model. The AUC scores indicate overall model performance, with higher values reflecting better predictive power.</p>


    <h4>Key Insights</h4>
    <p>Gradient boosting models (CatBoost, HistGB, LightGBM) outperformed logistic regression, highlighting the effectiveness of tree-based ensemble methods in credit risk prediction. CatBoost achieved the highest AUC, suggesting its suitability for handling categorical data and complex interactions.</p>

    </section>
    <section id="conclusion">
            <h2>Conclusion</h2>
            <p>Our research highlights that incorporating detailed bank transaction data into credit scoring models results
                 in performance that is comparable to traditional models, all without the necessity of credit history. 
                 This innovative approach allows for a more comprehensive and nuanced assessment of an individual’s 
                 creditworthiness, providing a more holistic view of their financial behavior. By utilizing transactional 
                 data, we aim to improve the accuracy of credit scoring, offering a more transparent and equitable evaluation 
                 process. This model addresses existing biases and limitations in traditional credit scoring, especially for 
                 individuals with limited or no credit history, such as young adults or those from underrepresented groups. 
                 Ultimately, this approach seeks to enhance fairness and inclusivity within the financial system, increasing 
                 access to credit opportunities for those who have historically been overlooked or excluded from traditional 
                 lending practices.</p>
            <h3>Next Steps</h3>
            <ul>
                <li><strong>Feature Engineering:</strong> We aim to optimize aggregated feature metrics based on transaction categories and time windows. Additionally, we plan to implement clustering algorithms to identify and select the most relevant features for improved model performance.</li>
                <li><strong>Model Refinement:</strong> We intend to explore deep learning models, incorporating extended hyperparameter tuning sessions to uncover more complex patterns in the data and improve predictive accuracy.</li>
                <li><strong>Bias & Fairness:</strong> To ensure equitable credit assessments, we will evaluate the potential for biases in predictions across different demographic groups and implement fairness constraints to mitigate any identified disparities.</li>
            </ul>
            
                
        </section>
        
        <section class="team">
            <h2>Our Team</h2>
            <div class="team-container">
                <div class="team-member">
                    <img src="figures/akar.jpeg" alt="Aman Kar">
                    <h3>Aman Kar</h3>
                    <a href="https://www.linkedin.com/in/aman-kar" target="_blank" class="linkedin-icon">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </div>
                <div class="team-member">
                    <img src="figures/drm.jpeg" alt="Daniel Mathew">
                    <h3>Daniel Mathew</h3>
                    <a href="https://www.linkedin.com/in/daniel-roy-mathew" target="_blank" class="linkedin-icon">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </div>
                <div class="team-member">
                    <img src="figures/tnp.jpeg" alt="Tracy Pham">
                    <h3>Tracy Pham</h3>
                    <a href="https://www.linkedin.com/in/tracy-pham-3aa505221/" target="_blank" class="linkedin-icon">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </div>
            </div>
        </section>
        
        
    </main>
    <script src="script.js"></script>
</body>
</html>
