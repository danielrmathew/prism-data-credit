<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building Better Credit Scores</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-..." crossorigin="anonymous" referrerpolicy="no-referrer" />

</head>
<body>
    <header>
        <div class="overlay"></div>
        <div class="text-box">
            <h1>Building Better Credit Scores</h1>
            <h2>Machine Learning and NLP for Optimized Risk Assessment</h2>
            <p>By Aman Kar, Daniel Mathew, Tracy Pham</p>
            <a href="https://github.com/danielrmathew/prism-data-credit" target="_blank" class="github-link">
                <img src="figures/github-mark-white.png" alt="GitHub Logo" class="github-logo">
                View on GitHub
            </a>
        </div>
    </header>
       
    <nav class="navbar">
        <ul>
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#methods">Methods</a></li>
            <li><a href="#models">Models</a></li>
            <li><a href="#results">Results</a></li>
            <li><a href="#conclusion">Conclusion</a></li>
        </ul>
    </nav>
    <main>
        <section id="introduction">
            <h2>Introduction</h2>
            <figure class="image-group">
                <img src="figures/traditional-model.png" alt="Traditional Credit Scoring Model (FICO Score)">
                <figcaption>Traditional Credit Scoring Model (FICO Score)</figcaption>
            </figure>
            <p>Credit scores are pivotal in today’s financial landscape, influencing everything from rental eligibility to access to 
                health insurance, yet the formula for calculating creditworthiness has long been shrouded in mystery and often overlooks 
                important nuances. Typically, the credit score is determined based on five factors: payment history, amount owed, new 
                credit, credit history, and credit mix. This structure can place individuals with limited credit history, especially 
                young adults who are just starting out building their credit, at a compounded disadvantage, restricting their access to 
                loans, credit cards, employment opportunities, and insurance. Our proposed Cash Score model aims to address these limitations by 
                providing a more comprehensive measure of creditworthiness. The Cash Score model leverages detailed account transaction 
                data to predicts the probability of defaulting on a loan (as known as loan delinquency). This approach highlights 
                the potential for transaction-based credit evaluation to more accurately assess financial risk and improve access to credit, 
                offering a fairer alternative to traditional credit scoring methods.</p>
            <figure class="improved-model">
                <img src="figures/model-pipeline.png" alt="Cash Score Model Pipeline">
                <figcaption>Cash Score Model Pipeline</figcaption>
            </figure>
            We adopted an iterative approach to model development, emphasizing continuous refinement and enhancement
            of features alongside model selection and performance evaluation. We began with logistic regression to establish a 
            baseline and identify key features. As the process evolved, we integrated more advanced algorithms like 
            HistGradientBoosting (HistGB), CatBoost, LightGBM, and XGBoost, chosen for their ability to handle complex data patterns.
            Throughout the iterations, we focused on refining and enhancing feature generation, selecting the most relevant ones to 
            improve the model’s performance. This iterative process allows us to optimize the model’s predictive power.
        </section>

        <section id="methods">
            <h2>Methods</h2>
            <h3>Data Description</h3>
            <p>Our analysis leverages four key datasets that provide insights into consumer accounts, transaction
                histories, and credit scores. As the datasets were prepared and preprocessed by Prism
                Data, this minimized the need for extensive data cleaning. Our primary focus in terms of
                data cleaning was reviewing the data for consistency, addressing any remaining missing
                values, standardizing categorical variables, and structuring time-series data to optimize it
                for modeling.</p>

            <p>Below are the heads of the datasets used in this analysis. Click on each section 
                to expand and view the data:</p>
                <div class="accordion-container">
                    <div class="accordion">
                        <button class="accordion-btn">Account Dataset</button>
                        <div class="panel">
                            <table>
                                <thead>
                                    <tr>
                                        <th>prism_consumer_id</th>
                                        <th>prism_account_id</th>
                                        <th>account_type</th>
                                        <th>balance_date</th>
                                        <th>balance</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr><td>3,023</td><td>0</td><td>SAVINGS</td><td>2021-08-31</td><td>90.57</td></tr>
                                    <tr><td>3,023</td><td>1</td><td>CHECKING</td><td>2021-08-31</td><td>225.95</td></tr>
                                    <tr><td>4,416</td><td>2</td><td>SAVINGS</td><td>2022-03-31</td><td>15,157.17</td></tr>
                                    <tr><td>4,416</td><td>3</td><td>CHECKING</td><td>2022-03-31</td><td>66.42</td></tr>
                                    <tr><td>4,227</td><td>4</td><td>CHECKING</td><td>2021-07-31</td><td>7,042.90</td></tr>
                                </tbody>
                            </table>
                            The acctDF.csv dataset provides detailed information about consumer financial accounts,
                            such as account types, balances, and balance dates.
                        </div>
                    </div>
                
                    <div class="accordion">
                        <button class="accordion-btn">Consumer Dataset</button>
                        <div class="panel">
                            <table>
                                <thead>
                                    <tr>
                                        <th>prism_consumer_id</th>
                                        <th>evaluation_date</th>
                                        <th>credit_score</th>
                                        <th>DQ_TARGET</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr><td>0</td><td>2021-09-01</td><td>726</td><td>0</td></tr>
                                    <tr><td>1</td><td>2021-07-01</td><td>626</td><td>0</td></tr>
                                    <tr><td>2</td><td>2021-05-01</td><td>680</td><td>0</td></tr>
                                    <tr><td>3</td><td>2021-03-01</td><td>734</td><td>0</td></tr>
                                    <tr><td>4</td><td>2021-10-01</td><td>676</td><td>0</td></tr>
                                </tbody>
                            </table>
                            The consDF.csv dataset which provides credit scores, evaluation
                            dates, and delinquency targets for each consumer. This dataset is essential for building a
                            model of credit risk, as it contains direct indicators of a consumer’s creditworthiness. The
                            delinquency targets serves as the dependent variable, enabling us to assess our model’s per-
                            formance in predicting credit risk.
                                                    </div>
                    </div>
                
                    <div class="accordion">
                        <button class="accordion-btn">Transaction Dataset</button>
                        <div class="panel">
                            <table>
                                <thead>
                                    <tr>
                                        <th>prism_consumer_id</th>
                                        <th>prism_transaction_id</th>
                                        <th>category</th>
                                        <th>amount</th>
                                        <th>credit_or_debit</th>
                                        <th>posted_date</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr><td>3,023</td><td>0</td><td>4</td><td>0.05</td><td>CREDIT</td><td>2021-04-16</td></tr>
                                    <tr><td>3,023</td><td>1</td><td>12</td><td>481.56</td><td>CREDIT</td><td>2021-04-30</td></tr>
                                    <tr><td>3,023</td><td>2</td><td>4</td><td>0.05</td><td>CREDIT</td><td>2021-05-16</td></tr>
                                    <tr><td>3,023</td><td>3</td><td>4</td><td>0.07</td><td>CREDIT</td><td>2021-06-16</td></tr>
                                    <tr><td>3,023</td><td>4</td><td>4</td><td>0.06</td><td>CREDIT</td><td>2021-07-16</td></tr>
                                </tbody>
                            </table>
                            The trxnDF.csv dataset records individual transactions, including
                            transaction category IDs, amounts, and whether the transaction was a credit or debit. These
                            transactional data are vital for modeling consumer behavior, such as income sources, spend-
                            ing habits, and cash flow.
                        </div>
                    </div>
                
                    <div class="accordion">
                        <button class="accordion-btn">Category Mappings</button>
                        <div class="panel">
                            <table>
                                <thead>
                                    <tr>
                                        <th>category_id</th>
                                        <th>category</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr><td>0</td><td>SELF_TRANSFER</td></tr>
                                    <tr><td>1</td><td>EXTERNAL_TRANSFER</td></tr>
                                    <tr><td>2</td><td>DEPOSIT</td></tr>
                                    <tr><td>3</td><td>PAYCHECK</td></tr>
                                    <tr><td>4</td><td>MISCELLANEOUS</td></tr>
                                </tbody>
                            </table>
                            The cat_map.csv dataset maps transaction categories to their corresponding category IDs, allowing us to classify and interpret the transactions effectively.
                        </div>
                    </div>
                </div>
    
    <p>It is important to note that, in compliance with the <strong>Equal Credit Opportunity Act (ECOA)</strong>,
        we excluded specific transaction categories that could introduce bias in credit decision-making. 
        Categories related to child dependents, healthcare and medical expenses, unemployment benefits, education,
        and pensions have been removed to ensure that our model does not unintentionally discriminate based on 
        protected attributes.</p>
            
        <h3>Exploratory Data Analysis</h3>
<p>Through exploratory data analysis (EDA), we examined consumer transaction trends and spending patterns to uncover insights that aid in identifying key factors for predicting credit risk. Below are a few examples of EDA conducted to look at temporal trends, transaction frequency, spending categories, and the impact of specific financial behaviors.</p>

<div class="carousel-container">
    <div class="carousel-item">
        <div class="carousel-img">
            <img src="figures/goodbad_diff.png" alt="Balance Over Time of Delinquent vs. Non-Delinquent Consumer">
        </div>
        <div class="carousel-text">
            <p>Comparing bank balances over time between a randomly selected delinquent and non-delinquent consumer reveals distinct financial patterns. The delinquent consumer’s balance remains mostly stagnant, with a single large spike that quickly drops. In contrast, the non-delinquent consumer maintains a steady, positive balance with gradual growth, indicating stable income, controlled spending, and savings. This suggests that bank balance trends can serve as a strong predictor of creditworthiness.</p>
        </div>
    </div>

    <div class="carousel-item">
        <div class="carousel-img">
            <img src="figures/ks_cscore.png" alt="Distribution of Credit Score by Delinquency Status">
        </div>
        <div class="carousel-text">
            <p>The normal distribution of delinquent credit scores, compared to the left-skewed distribution of non-delinquent credit scores, shows that non-delinquent individuals typically have higher credit scores, while most delinquent individuals fall within the lower middle of the credit score range. This reinforces that credit scores are already a strong indicator of delinquency. This provides a foundation for our model, allowing us to build upon the credit score feature to potentially outperform traditional models at predicting delinquency.</p>
        </div>
    </div>

    <div class="carousel-item">
        <div class="carousel-img">
            <img src="figures/BNPL_last_14_days_mean_distribution.png" alt="Distribution of BNPL_last_14_days_mean">
        </div>
        <div class="carousel-text">
            <p>Identifying "Buy Now, Pay Later" (BNPL) as a risky category, we analyzed this category further. The figure reveals that a significantly higher proportion of non-delinquent consumers fall into the lowest bin for mean BNPL transactions. However, delinquent consumers tend to have higher proportions in the upper bins, indicating that they engage in larger BNPL transactions compared to non-delinquent consumers.</p>
        </div>
    </div>

    <div class="carousel-item">
        <div class="carousel-img">
            <img src="figures/TAX_last_14_days_count_distribution.png" alt="Distribution of TAX_last_14_days_count">
        </div>
        <div class="carousel-text">
            <p>The plot reveals a wider range of tax transactions over the last two weeks for non-delinquent consumers, while delinquent consumers show little to no variation in their tax transaction frequency. This suggests that non-delinquent consumers are more active and consistent in handling their tax-related transactions, which could indicate better financial management and stability compared to delinquent consumers.</p>
        </div>
    </div>

    <div class="carousel-buttons">
        <button class="prev-button" onclick="moveCarousel(-1)">Previous</button>
        <span class="carousel-indicator">1/4</span> <!-- Shows the current image number -->
        <button class="next-button" onclick="moveCarousel(1)">Next</button>
    </div>
</div>



            <h3>Feature Generation</h3>
            <p>We engineered features to capture financial behavior through transaction history, balance trends, 
                spending patterns, and risk indicators. Our feature generation process included:</p>
            
            <ul>
                <li><strong>Time Window Analysis:</strong> Transactions were analyzed across multiple time windows—14 
                    days, 30 days, 3 months, 6 months, and 1 year—to capture short- and long-term trends.</li>
                <li><strong>Aggregated Statistics:</strong> Summary statistics (minimum, maximum, mean, median, standard 
                    deviation, sum, count, percent of transactions) are calculated on categorical and balance trends.
    
                    <figure class="feat-gen-img-container">
                        <img src="figures/features-diagram.png" alt="Category-Based Feature Generation Process">
                        <figcaption>Category-Based Feature Generation Process</figcaption>
                    </figure>
                    <p>This diagram showcases our process for generating category-based features. For example, one of
                        the features created through this process is FOOD_BEVERAGES_last_14_days_mean, which
                        represents the average transaction amount within the “Food & Beverages” category over
                        the past 14 days. By analyzing these features, we aim to capture spending habits, identify
                        fluctuations in financial stability, and differentiate between various financial behaviors.</p>

                <li><strong>Risk Indicators:</strong> High-risk behaviors were identified through flagged transactions, 
                    such as gambling, using threshold-based indicators.</li>

                <li><strong>Balance Features:</strong> Features that reflect balance fluctuations such
                     as balance deltas, rolling averages, and recent trends were created.

                <li><strong>Income Features:</strong> Income-based features such as the number of income sources and income
                standard deviation were calculated to assess the diversity and variability of a consumer’s
                income.</li> 
                <li><strong>Standardization:</strong> Non-categorical features were standardized to ensure consistent 
                            scaling.</li>
                <li><strong>Resampling:</strong> Our dataset had an imbalance, meaning one class had much more data than 
                    the other. To fix this, we used Sythethic Minority Over-Sampling Technique (SMOTE) to generate new samples for the smaller group and undersampling
                     to reduce the larger group. This helped create a more balanced dataset, allowing the model to learn 
                     patterns more effectively without bias.</li>
            </ul>

            <h3>Feature Selection</h3>
            <p>The final dataset contained more than 2,000 features, with the dataframe shape being
                15000 rows × 2430 columns. To refine model input, we performed feature selection using the following techniques:</p>
            <ul>
                <li><strong>Correlation Analysis:</strong> Selected top features most correlated with delinquency using Lasso (L1) Regularization.</li>
                <li><strong>Mutual Information:</strong> Identified features with the highest mutual information score for predictive power.</li>
                <li><strong>Embedded Method:</strong> Utilized Random Forest to rank and select the most relevant features.</li>
            </ul>
        </section>
        
        
        <section id="models">
            <h2>Models</h2>
            <p>We evaluated multiple machine learning models to predict credit risk. 
                Below is a brief description of each model used in our analysis.</p>
        
                <h3>Modeling Approaches</h3>
<ul>
    <li><strong>Baseline Model: Logistic Regression</strong>: A simple yet effective linear model that serves as the starting point for comparison with more advanced models.</li>
    <li><strong>Histogram-based Gradient Boosting (HistGB)</strong>: Speeds up training by grouping data into bins, working well for large datasets and making the model faster and more memory-efficient.</li>
    <li><strong>Categorical Boosting (CatBoost)</strong>: A gradient boosting method specifically designed for categorical data, preventing overfitting and building more balanced trees for better predictions.</li>
    <li><strong>Light Gradient-Boosting Machine (LightGBM)</strong>: Uses "leaf-wise" decision trees for faster learning and reduced memory usage, making it particularly effective for large datasets.</li>
    <li><strong>Extreme Gradient Boosting (XGBoost)</strong>: A popular gradient boosting method known for its speed and accuracy. It reduces errors through regularization and handles large datasets efficiently by running in parallel on multiple processors.</li>
</ul>
<p>Each of these models (other than Logistic Regression) improves upon regular decision trees by using "boosting" to combine multiple trees, which enhances the model's accuracy.</p>
                <h3>Model Evaluation</h3>
                <p>We used the following metrics to assess model performance:</p>
                <ul>
                    <li><strong>ROC AUC</strong>: Shows how well the model can tell the difference between positive and negative outcomes. Higher values mean the model is better at making this distinction.</li>
                    <li><strong>Accuracy</strong>: Tells us the percentage of times the model made a correct prediction.</li>
                    <li><strong>Precision</strong>: Measures how many of the model's positive predictions were actually correct.</li>
                    <li><strong>Recall</strong>: Shows how many of the actual positive cases were correctly identified by the model.</li>
                    <li><strong>Confusion Matrix</strong>: A table that helps us see how many predictions were correct and how many were wrong, broken down by type of error (false positive, false negative).</li>
                </ul>

        </section>
        
    <section id="results">
<h2>Results</h2>

<h3>Feature Importance</h3>

<details>
    <summary style="cursor: pointer; font-size: 1.1em; font-weight: bold; color: #2471a3;">
        Click to expand
    </summary>

    <div style="text-align: center; margin-top: 10px;">
        <img src="figures/shap_values_normal.png" alt="Top SHAP Values" style="width: 40%;">
        <p><strong>Figure:</strong> Top SHAP Values</p>
    </div>

    <p>
        SHAP (SHapley Additive exPlanations) is a method used to explain model predictions by attributing each feature's contribution to the final prediction.
    </p>

    <p>In our model, SHAP identified the following features to be important in predicting credit delinquency:</p>

    <ul>
        <li><strong>sum_acct_balances:</strong> Higher account balances suggest lower delinquency risk.</li>
        <li><strong>HAS_SAVINGS_ACCT:</strong> Having a savings account reduces delinquency risk.</li>
        <li><strong>DEPOSIT_last_14_days_count:</strong> Recent deposits indicate financial stability.</li>
        <li><strong>OVERDRAFT:</strong> Frequent overdrafts increase delinquency risk.</li>
        <li><strong>LOAN_last_14_days_count:</strong> Recent loans may signal financial stress.</li>
    </ul>

</details>

    <h3>Model Performance</h3>

    </p>
            <div class="results-img-container">

                <img src="figures/auc-roc-credit-score.png" alt="Results">
                <img src="figures/roc_auc_no_cs_models.png" alt="Results">

            </div>
    <p>The ROC curves below illustrate the trade-off between the true positive rate and the false positive rate for each model. The AUC scores indicate overall model performance, with higher values reflecting better predictive power.</p>

    <table border="1" cellpadding="5" cellspacing="0" style="border-collapse: collapse; font-size: 0.9em; width: 100%;">
        <caption><strong>Model Performance Metrics Comparison</strong></caption>
        <thead>
            <tr>
                <th><strong>Model</strong></th>
                <th><strong>ROC-AUC</strong></th>
                <th><strong>Accuracy</strong></th>
                <th><strong>Precision</strong></th>
                <th><strong>Recall</strong></th>
                <th><strong>F1-Score</strong></th>
                <th><strong>Training</strong></th>
                <th><strong>Prediction</strong></th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Logistic Regression (w/o Credit Score)</td>
                <td>0.7079</td>
                <td>0.8445</td>
                <td>0.2383</td>
                <td>0.2785</td>
                <td>0.2568</td>
                <td>1.3368</td>
                <td>0.4016</td>
            </tr>
            <tr style="background-color: #E0F7FA;">
                <td>Logistic Regression (w/ Credit Score)</td>
                <td>0.7241</td>
                <td>0.8571</td>
                <td>0.2674</td>
                <td>0.3548</td>
                <td>0.3050</td>
                <td>1.7175</td>
                <td>0.3315</td>
            </tr>
            <tr>
                <td>LightGBM (w/o Credit Score)</td>
                <td>0.7796</td>
                <td>0.8991</td>
                <td>0.3878</td>
                <td>0.0802</td>
                <td>0.1329</td>
                <td>4.1249</td>
                <td>0.0931</td>
            </tr>
            <tr style="background-color: #E0F7FA;">
                <td>LightGBM (w/ Credit Score)</td>
                <td>0.8162</td>
                <td>0.9068</td>
                <td>0.4167</td>
                <td>0.1382</td>
                <td>0.2076</td>
                <td>3.9720</td>
                <td>0.0859</td>
            </tr>
            <tr style="font-weight: bold;">
                <td>CatBoost (w/o Credit Score)</td>
                <td>0.7704</td>
                <td>0.9019</td>
                <td>0.4474</td>
                <td>0.0717</td>
                <td>0.1236</td>
                <td>38.6703</td>
                <td>0.0788</td>
            </tr>
            <tr style="background-color: #E0F7FA; font-weight: bold;">
                <td>CatBoost (w/ Credit Score)</td>
                <td>0.8260</td>
                <td>0.9170</td>
                <td>0.4681</td>
                <td>0.1095</td>
                <td>0.1774</td>
                <td>40.9512</td>
                <td>0.0960</td>
            </tr>
        </tbody>
    </table>
    
    <p><strong>Key Insights:</strong></p>
    <ul>
        <li>Adding credit scores improves model performance, helping predict delinquency more accurately for all models.</li>
        <li>CatBoost (with credit score as a feature) is the most accurate model, with the highest AUC-ROC score, but struggles to detect delinquent cases and takes longer to train.</li>
        <li>Without credit scores, LightGBM performs best. Compared to CatBoost, the training time is also significantly lower.</li>
    </ul>
    
    <h3>Futher Analysis: Confusion Matrices</h3>

    <details>
        <summary style="cursor: pointer; font-size: 1.1em; font-weight: bold; color: #2471a3;">
            Click to expand
        </summary>
    
        <div style="display: flex; justify-content: center; gap: 1rem; margin-top: 10px;">
            <div style="text-align: center;">
                <img src="figures/CatBoost_cash_cm_normal.png" alt="CatBoost Confusion Matrix without Credit Score" style="width: 50%;">
                <p>CatBoost (w/o Credit Score)</p>
            </div>
            <div style="text-align: center;">
                <img src="figures/CatBoost_cs_cm_normal.png" alt="CatBoost Confusion Matrix with Credit Score" style="width: 50%;">
                <p>CatBoost (w/ Credit Score)</p>
            </div>
        </div>
    
        <div style="display: flex; justify-content: center; gap: 1rem; margin-top: 10px;">
            <div style="text-align: center;">
                <img src="figures/LightGBM_cash_cm_normal.png" alt="LightGBM Confusion Matrix without Credit Score" style="width: 50%;">
                <p>LightGBM (w/o Credit Score)</p>
            </div>
            <div style="text-align: center;">
                <img src="figures/LightGBM_cs_cm_normal.png" alt="LightGBM Confusion Matrix with Credit Score" style="width: 50%;">
                <p>LightGBM (w/ Credit Score)</p>
            </div>
        </div>
    
        <p>
            From the confusion matrices, we observe that both CatBoost and LightGBM improve slightly with credit score inclusion. However, they remain highly conservative, predicting very few positive cases. This results in high precision but low recall as seen in the model performance table.
        </p>
    
        <p><strong>Note:</strong> In these models, "positive" refers to delinquent cases, while "negative" represents non-delinquent cases.</p>
    
    </details>
    
    <h3>Cash Score vs. Credit Score</h3>
        <div style="display: flex; justify-content: center; gap: 1rem;">
            <div style="text-align: center;">
                <img src="figures/delinquency_rate_heatmap.png" alt="Delinquency Rate Heatmap" style="width: 35%;">
                <p>Delinquency Rate Heatmap (Cash Score vs. Credit Score)</p>
            </div>
        </div>
        The heatmap visually represents delinquency rates using color intensity and numerical values, where darker regions indicate higher delinquency. The bottom-left region, where scores are lowest, shows delinquency reaching 100%, while the top-right region, representing higher scores, exhibits near-zero delinquency. This highlights both cash and credit scores as strong indicators of financial risk, with higher scores consistently associated with lower delinquency rates.

    </section>
    <section id="conclusion">
            <h2>Conclusion</h2>
            <p>Our research highlights that incorporating detailed bank transaction data into credit scoring models results
                 in performance that is comparable to traditional models, all without the necessity of credit history. 
                 This approach allows for a more comprehensive and nuanced assessment of an individual’s 
                 creditworthiness, providing a more holistic view of their financial behavior. By utilizing transactional 
                 data, we aim to improve the accuracy of credit scoring, offering a more transparent and equitable evaluation 
                 process. This model addresses existing biases and limitations in traditional credit scoring, especially for 
                 individuals with limited or no credit history, such as young adults or those from underrepresented groups. 
                 Ultimately, this approach seeks to enhance fairness and inclusivity within the financial system, increasing 
                 access to credit opportunities for those who have historically been overlooked or excluded from traditional 
                 lending practices.</p>
            <h3>Next Steps</h3>
            <ul>
                <li><strong>Feature Engineering:</strong> We aim to optimize aggregated feature metrics based on transaction categories and time windows. Additionally, we plan to implement clustering algorithms to identify and select the most relevant features for improved model performance.</li>
                <li><strong>Model Refinement:</strong> We intend to explore deep learning models, incorporating extended hyperparameter tuning sessions to uncover more complex patterns in the data and improve predictive accuracy.</li>
                <li><strong>Bias & Fairness:</strong> To ensure equitable credit assessments, we will evaluate the potential for biases in predictions across different demographic groups and implement fairness constraints to mitigate any identified disparities.</li>
            </ul>
            
        </section>
        
        <section class="team">
            <h2>Our Team</h2>
            <div class="team-container">
                <div class="team-member">
                    <img src="figures/akar.jpeg" alt="Aman Kar">
                    <h3>Aman Kar</h3>
                    <p>akar@ucsd.edu</p>
                    <a href="https://www.linkedin.com/in/aman-kar" target="_blank" class="linkedin-icon">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </div>
                <div class="team-member">
                    <img src="figures/drm.jpeg" alt="Daniel Mathew">
                    <h3>Daniel Mathew</h3>
                    <p>drmathew@ucsd.edu</p>
                    <a href="https://www.linkedin.com/in/daniel-roy-mathew" target="_blank" class="linkedin-icon">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </div>
                <div class="team-member">
                    <img src="figures/tnp.jpeg" alt="Tracy Pham">
                    <h3>Tracy Pham</h3>
                    <p>tnp003@ucsd.edu</p>
                    <a href="https://www.linkedin.com/in/tracy-pham-3aa505221/" target="_blank" class="linkedin-icon">
                        <i class="fab fa-linkedin"></i>
                    </a>
                </div>
            </div>
        </section>
        
        
    </main>
    <script src="script.js"></script>
</body>
</html>
